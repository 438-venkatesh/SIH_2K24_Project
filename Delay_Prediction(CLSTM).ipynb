{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/438-venkatesh/SIH_2K24_Project/blob/main/Delay_Prediction(CLSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7muaTFESd-62",
        "outputId": "7cfb2e53-f170-4e3c-eecd-d9d6a97151b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tq_OZYoU9SgA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Dense, Dropout, Input, Attention, LayerNormalization, Concatenate,Flatten,Conv1D,Bidirectional\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import Huber\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D, Reshape, Multiply"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/bus_delay_data - bus_delay_data.csv')\n",
        "X = data[['Time','Traffic Density (vehicles/km)','Bus Speed (km/h)','Weather Type']]\n",
        "y = data['Historical Delay (min)']"
      ],
      "metadata": {
        "id": "zVb9nirr9Vh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_to_float(time_str):\n",
        "    try:\n",
        "      time_obj = datetime.strptime(time_str, '%H:%M:%S')\n",
        "      return time_obj.hour + time_obj.minute / 60.0 + time_obj.second / 3600.0\n",
        "    except ValueError:\n",
        "      print(f\"Invalid time format: {time_str}\")\n",
        "      return None"
      ],
      "metadata": {
        "id": "Tc9on0eU92qL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X['time_float'] = X['Time'].apply(time_to_float)\n",
        "X = X.drop(columns=['Time'])\n",
        "\n",
        "#X = pd.get_dummies(X, columns=['Weather Type'], prefix='Weather')\n",
        "\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "X_scaled = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
        "\n",
        "X_train, X_test, y_train_scaled, y_test_scaled = train_test_split(\n",
        "    X_scaled, y_scaled, test_size=0.2, random_state=42\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "w-22Trx_-E2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKJeuotgQbuw",
        "outputId": "a10b134d-3f60-43c6-d4cf-37fc9391c8c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-6IDXknQe52",
        "outputId": "1da615ed-f93e-434d-d537-9906ee9bcc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clstm_model_builder(hp):\n",
        "    input_layer = Input(shape=(X_train.shape[1],4))\n",
        "\n",
        "    # 1D Convolutional Layer for feature extraction\n",
        "    hp_filters = hp.Int('filters', min_value=16, max_value=128, step=16)\n",
        "    hp_kernel_size = hp.Choice('kernel_size', values=[3, 5, 7])\n",
        "    conv1 = Conv1D(filters=hp_filters, kernel_size=hp_kernel_size, activation='elu',\n",
        "                   padding='same', kernel_initializer='he_normal')(input_layer)\n",
        "    conv1 = LayerNormalization()(conv1)\n",
        "\n",
        "    # First Bidirectional LSTM Layer\n",
        "    hp_units1 = hp.Int('units1', min_value=32, max_value=256, step=32)\n",
        "    lstm1 = Bidirectional(LSTM(units=hp_units1, return_sequences=True,\n",
        "                               kernel_initializer='he_normal'))(conv1)\n",
        "    ln1 = LayerNormalization()(lstm1)\n",
        "\n",
        "    # Residual connection from conv1 to lstm1 output\n",
        "    residual1 = Concatenate()([conv1, ln1])\n",
        "\n",
        "    # Second Bidirectional LSTM Layer\n",
        "    hp_units2 = hp.Int('units2', min_value=32, max_value=256, step=32)\n",
        "    lstm2 = Bidirectional(LSTM(units=hp_units2, return_sequences=True,\n",
        "                               kernel_initializer='he_normal'))(residual1)\n",
        "    ln2 = LayerNormalization()(lstm2)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    attention = GlobalAveragePooling1D()(ln2)\n",
        "    attention = Dense(hp_units2, activation='elu')(attention)\n",
        "    attention = Dense(X_train.shape[1], activation='softmax')(attention)\n",
        "    attention = Reshape((X_train.shape[1], 1))(attention)\n",
        "    attention_output = Multiply()([ln2, attention])\n",
        "\n",
        "    # Final Dense Layer after Attention\n",
        "    ln3 = LayerNormalization()(attention_output)\n",
        "    ln3 = Dropout(rate=hp.Choice('dropout', values=[0.2, 0.3, 0.4]))(ln3)\n",
        "    dense_output = Dense(64, activation='elu', kernel_initializer='he_normal')(ln3)\n",
        "    dense_output = Dense(1, activation='linear', kernel_initializer='he_normal')(dense_output)\n",
        "\n",
        "    # Output Layer\n",
        "    output = Dense(1, activation='linear')(dense_output)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "    # Optimizer with Learning Rate Tuning\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
        "    optimizer = Adam(learning_rate=hp_learning_rate)\n",
        "\n",
        "    # Compile Model with Parameterized Huber Loss\n",
        "    hp_delta = hp.Choice('delta', values=[0.5, 1.0, 1.5])\n",
        "    model.compile(optimizer=optimizer, loss=Huber(delta=hp_delta))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "kwKAZMNqccyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    clstm_model_builder,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,  # Reduced max_trials for faster tuning\n",
        "    executions_per_trial=1, # Increase to 2 or 3 for increased reliability\n",
        "    overwrite = True, # Add this to avoid error if running multiple times\n",
        "    directory='my_dir_clstm',\n",
        "    project_name='tune_clstm'\n",
        ")"
      ],
      "metadata": {
        "id": "ap2qcMpdDCjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train_scaled, epochs=50, validation_data=(X_test, y_test_scaled),\n",
        "             callbacks=[EarlyStopping(patience = 10)], verbose =1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiH5h2Y9-ccs",
        "outputId": "41459d76-44fe-4b45-8b27-49f5bbcb80ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 29s]\n",
            "val_loss: 0.03177684172987938\n",
            "\n",
            "Best val_loss So Far: 0.007567976135760546\n",
            "Total elapsed time: 00h 09m 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "metadata": {
        "id": "gONan-4RCDMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "lr_schedule = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-7)\n",
        "\n",
        "history = model.fit(X_train, y_train_scaled, epochs=100, batch_size=best_hps.get(\"units1\"),  validation_data=(X_test, y_test_scaled),\n",
        "                    callbacks=[early_stopping, lr_schedule], verbose =1)\n",
        "\n",
        "model.save(\"final.h5\")"
      ],
      "metadata": {
        "id": "ai-N40HC-fSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79737430-e8fc-43b3-b41c-90d01fe8d689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - loss: 0.1467 - val_loss: 0.0494 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0382 - val_loss: 0.0390 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0360 - val_loss: 0.0400 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0335 - val_loss: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0337 - val_loss: 0.0372 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0324 - val_loss: 0.0361 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0307 - val_loss: 0.0366 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0297 - val_loss: 0.0358 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - loss: 0.0292 - val_loss: 0.0348 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0274 - val_loss: 0.0346 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0286 - val_loss: 0.0340 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0269 - val_loss: 0.0349 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0260 - val_loss: 0.0336 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0277 - val_loss: 0.0330 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0264 - val_loss: 0.0328 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0282 - val_loss: 0.0310 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0259 - val_loss: 0.0312 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0242 - val_loss: 0.0301 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0234 - val_loss: 0.0306 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0222 - val_loss: 0.0295 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0235 - val_loss: 0.0289 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0203 - val_loss: 0.0276 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0217 - val_loss: 0.0272 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0212 - val_loss: 0.0268 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0228 - val_loss: 0.0258 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0201 - val_loss: 0.0257 - learning_rate: 0.0010\n",
            "Epoch 27/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0186 - val_loss: 0.0255 - learning_rate: 0.0010\n",
            "Epoch 28/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0188 - val_loss: 0.0248 - learning_rate: 0.0010\n",
            "Epoch 29/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: 0.0202 - val_loss: 0.0242 - learning_rate: 0.0010\n",
            "Epoch 30/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - loss: 0.0192 - val_loss: 0.0227 - learning_rate: 0.0010\n",
            "Epoch 31/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0180 - val_loss: 0.0229 - learning_rate: 0.0010\n",
            "Epoch 32/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.0170 - val_loss: 0.0220 - learning_rate: 0.0010\n",
            "Epoch 33/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0159 - val_loss: 0.0219 - learning_rate: 0.0010\n",
            "Epoch 34/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.0183 - val_loss: 0.0214 - learning_rate: 0.0010\n",
            "Epoch 35/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0165 - val_loss: 0.0210 - learning_rate: 0.0010\n",
            "Epoch 36/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0150 - val_loss: 0.0205 - learning_rate: 0.0010\n",
            "Epoch 37/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0166 - val_loss: 0.0204 - learning_rate: 0.0010\n",
            "Epoch 38/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0147 - val_loss: 0.0188 - learning_rate: 0.0010\n",
            "Epoch 39/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0161 - val_loss: 0.0193 - learning_rate: 0.0010\n",
            "Epoch 40/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0153 - val_loss: 0.0182 - learning_rate: 0.0010\n",
            "Epoch 41/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0149 - val_loss: 0.0181 - learning_rate: 0.0010\n",
            "Epoch 42/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0147 - val_loss: 0.0186 - learning_rate: 0.0010\n",
            "Epoch 43/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0141 - val_loss: 0.0160 - learning_rate: 0.0010\n",
            "Epoch 44/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0136 - val_loss: 0.0171 - learning_rate: 0.0010\n",
            "Epoch 45/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0128 - val_loss: 0.0162 - learning_rate: 0.0010\n",
            "Epoch 46/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.0141 - val_loss: 0.0163 - learning_rate: 0.0010\n",
            "Epoch 47/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0123 - val_loss: 0.0162 - learning_rate: 0.0010\n",
            "Epoch 48/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0132 - val_loss: 0.0158 - learning_rate: 0.0010\n",
            "Epoch 49/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0124 - val_loss: 0.0159 - learning_rate: 0.0010\n",
            "Epoch 50/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0113 - val_loss: 0.0141 - learning_rate: 0.0010\n",
            "Epoch 51/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0103 - val_loss: 0.0150 - learning_rate: 0.0010\n",
            "Epoch 52/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0111 - val_loss: 0.0139 - learning_rate: 0.0010\n",
            "Epoch 53/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0096 - val_loss: 0.0132 - learning_rate: 0.0010\n",
            "Epoch 54/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - loss: 0.0097 - val_loss: 0.0144 - learning_rate: 0.0010\n",
            "Epoch 55/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0103 - val_loss: 0.0126 - learning_rate: 0.0010\n",
            "Epoch 56/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 0.0109 - val_loss: 0.0125 - learning_rate: 0.0010\n",
            "Epoch 57/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 0.0100 - val_loss: 0.0129 - learning_rate: 0.0010\n",
            "Epoch 58/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0096 - val_loss: 0.0122 - learning_rate: 0.0010\n",
            "Epoch 59/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - loss: 0.0105 - val_loss: 0.0124 - learning_rate: 0.0010\n",
            "Epoch 60/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0092 - val_loss: 0.0120 - learning_rate: 0.0010\n",
            "Epoch 61/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 0.0094 - val_loss: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 62/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0088 - val_loss: 0.0110 - learning_rate: 0.0010\n",
            "Epoch 63/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0092 - val_loss: 0.0103 - learning_rate: 0.0010\n",
            "Epoch 64/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0082 - val_loss: 0.0101 - learning_rate: 0.0010\n",
            "Epoch 65/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0081 - val_loss: 0.0100 - learning_rate: 0.0010\n",
            "Epoch 66/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0082 - val_loss: 0.0090 - learning_rate: 0.0010\n",
            "Epoch 67/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0081 - val_loss: 0.0089 - learning_rate: 0.0010\n",
            "Epoch 68/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0078 - val_loss: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 69/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0079 - val_loss: 0.0097 - learning_rate: 0.0010\n",
            "Epoch 70/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0078 - val_loss: 0.0074 - learning_rate: 0.0010\n",
            "Epoch 71/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0074 - val_loss: 0.0080 - learning_rate: 0.0010\n",
            "Epoch 72/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0069 - val_loss: 0.0104 - learning_rate: 0.0010\n",
            "Epoch 73/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0075 - val_loss: 0.0082 - learning_rate: 0.0010\n",
            "Epoch 74/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0070 - val_loss: 0.0093 - learning_rate: 0.0010\n",
            "Epoch 75/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0071 - val_loss: 0.0078 - learning_rate: 0.0010\n",
            "Epoch 76/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.0068 - val_loss: 0.0070 - learning_rate: 2.0000e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0052 - val_loss: 0.0068 - learning_rate: 2.0000e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0057 - val_loss: 0.0066 - learning_rate: 2.0000e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 63ms/step - loss: 0.0057 - val_loss: 0.0065 - learning_rate: 2.0000e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 0.0050 - val_loss: 0.0060 - learning_rate: 2.0000e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0054 - val_loss: 0.0060 - learning_rate: 2.0000e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0050 - val_loss: 0.0061 - learning_rate: 2.0000e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0051 - val_loss: 0.0060 - learning_rate: 2.0000e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - loss: 0.0049 - val_loss: 0.0057 - learning_rate: 2.0000e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0048 - val_loss: 0.0057 - learning_rate: 2.0000e-04\n",
            "Epoch 86/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0053 - val_loss: 0.0056 - learning_rate: 2.0000e-04\n",
            "Epoch 87/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.0047 - val_loss: 0.0058 - learning_rate: 2.0000e-04\n",
            "Epoch 88/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0051 - val_loss: 0.0052 - learning_rate: 2.0000e-04\n",
            "Epoch 89/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0043 - val_loss: 0.0052 - learning_rate: 2.0000e-04\n",
            "Epoch 90/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0044 - val_loss: 0.0050 - learning_rate: 2.0000e-04\n",
            "Epoch 91/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0052 - val_loss: 0.0052 - learning_rate: 2.0000e-04\n",
            "Epoch 92/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0048 - val_loss: 0.0051 - learning_rate: 2.0000e-04\n",
            "Epoch 93/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0045 - val_loss: 0.0047 - learning_rate: 2.0000e-04\n",
            "Epoch 94/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.0048 - val_loss: 0.0050 - learning_rate: 2.0000e-04\n",
            "Epoch 95/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0042 - val_loss: 0.0049 - learning_rate: 2.0000e-04\n",
            "Epoch 96/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0050 - val_loss: 0.0045 - learning_rate: 2.0000e-04\n",
            "Epoch 97/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.0041 - val_loss: 0.0047 - learning_rate: 2.0000e-04\n",
            "Epoch 98/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.0046 - val_loss: 0.0047 - learning_rate: 2.0000e-04\n",
            "Epoch 99/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0049 - val_loss: 0.0048 - learning_rate: 2.0000e-04\n",
            "Epoch 100/100\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.0047 - val_loss: 0.0044 - learning_rate: 2.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_scaled = model.predict(X_test)\n",
        "predictions_scaled = predictions_scaled.reshape(-1, 1)\n",
        "predictions = scaler_y.inverse_transform(predictions_scaled)\n",
        "\n",
        "mse = mean_squared_error(scaler_y.inverse_transform(y_test_scaled), predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(scaler_y.inverse_transform(y_test_scaled), predictions)\n",
        "print(f\"MSE: {mse}, RMSE: {rmse}, R2: {r2}\")"
      ],
      "metadata": {
        "id": "FpNIHTjw_d6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1237093c-7f6a-43c5-8406-e5852cb48b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 103ms/step\n",
            "MSE: 0.8893825073362239, RMSE: 0.9430707859626571, R2: 0.89912331954293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "N20kb1Ab_g1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "7fb7b7cd-ab9c-48f4-bf5e-1d61ab7dc6bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_delays = pd.DataFrame({\n",
        "    'Actual Delay (minutes)': scaler_y.inverse_transform(y_test_scaled).flatten(),\n",
        "    'Predicted Delay (minutes)': predictions.flatten()\n",
        "})"
      ],
      "metadata": {
        "id": "CVutrVfBAP26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_delays.head(20))"
      ],
      "metadata": {
        "id": "3k96G0YAAkwh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0308570-8465-4251-c9e9-d61d3e16af90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Actual Delay (minutes)  Predicted Delay (minutes)\n",
            "0                      8.0                   7.948194\n",
            "1                      1.0                   0.698742\n",
            "2                     10.0                   7.996514\n",
            "3                      5.0                   6.291009\n",
            "4                     10.0                   9.664246\n",
            "5                      5.0                   6.291009\n",
            "6                      0.0                   0.224029\n",
            "7                      5.0                   4.922752\n",
            "8                      3.0                   4.461099\n",
            "9                      7.0                   5.273107\n",
            "10                     9.0                   8.840487\n",
            "11                     3.0                   2.293165\n",
            "12                    10.0                   9.862350\n",
            "13                     2.0                   1.266753\n",
            "14                     4.0                   2.451283\n",
            "15                     5.0                   6.291009\n",
            "16                     5.0                   4.739423\n",
            "17                     3.0                   2.762134\n",
            "18                     1.0                   0.698742\n",
            "19                     5.0                   3.822991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing delay prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "NCa5rqBvb6C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model(\"/content/final.h5\")\n",
        "def time_to_float(time_str):\n",
        "    try:\n",
        "      time_obj = datetime.strptime(time_str, '%H:%M:%S')\n",
        "      return time_obj.hour + time_obj.minute / 60.0 + time_obj.second / 3600.0\n",
        "    except ValueError:\n",
        "      print(f\"Invalid time format: {time_str}\")\n",
        "      return None\n",
        "p=[\"9:30:00\",\"120\",\"5.5\",\"0\"]\n",
        "p[0]=time_to_float(p[0])\n",
        "p = [float(i) for i in p]\n",
        "p=np.array(p).reshape(1,1,4)\n",
        "o=model.predict(p)\n",
        "o = scaler_y.inverse_transform(o.reshape(-1,1))\n",
        "print(f\"{o[0][0]:.2f}\")"
      ],
      "metadata": {
        "id": "_8-es4dAN63y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26ec4a9f-4042-45c4-af85-ff26dba4adf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fa9b4a4ea70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745ms/step\n",
            "1.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9IpF391a5Ys",
        "outputId": "58f197ca-e8d0-46fd-804b-30d0575efd3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6RLpENobiIp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}